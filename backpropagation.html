<!doctype html>

<html>

<head>

    <title>Neural Networks and their applications</title>
    <link rel="stylesheet" type="text/css" href="css/main.css" />
    
    <script type="text/javascript" src="js/shCore.js"></script>
    <script type="text/javascript" src="js/shBrushDelphi.js"></script>
    <link rel="stylesheet" type="text/css" href="css/shCoreDefault.css" />
    <script type="text/javascript">SyntaxHighlighter.all()</script>
    
</head>

<body>

    <div id="wrapper">

        <div id="header">
            <a href="index.html"><img id="header"/></a>	 
        </div>

        <div id="navigation">

            <ul id="nav-one" class="nav">

                <li>
                    <a href="introduction.html">Introduction</a>
                </li>

                <li>
                    <a href="perceptrons.html">Perceptrons</a>
                </li>

                <li>
                    <a href="backpropagation.html">Backpropagation</a>
                </li>

                <li>
                    <a href="applet.html">Applet</a>
                </li>
                
            </ul>
            
        </div>
 
        <div id="faux">
        
            <div id="leftcolumn">
		    </div>
		    
		    <div id="content">

                <h1>Back propagation</h1>
                
                <p>
                    In large neural networks simulating more complex behaviours, finding the weights of each synapse is too complex
                    to be done manually, so instead the back propagation algorithm is commonly used to find weights which will
                    approximate the desired behaviour.
                </p>
                
                <p>
                    Back propagation is a supervised learning algorithm which works by calculating the difference between each output of
                    the network and the expected output for the inputs to the network, then propagating this error backwards
                    through the network to adjust the weights and reduce the error in the future. By repeating this train and test
                    loop over a large range of valid inputs, the neural network will learn the expected behaviour and the errors
                    will decrease.
                </p>
                
                <p>
                    Back propagation can be run for any number of valid inputs, however the network will eventually
                    reach a state where back propagation can no longer reduce the average error as shown below. In some cases,
                    the inputs used to
                    train the network can be picked randomly and the expected output can be found without manual intervention
                    since they are simple enough to calculate, e.g. a network trained to add numbers or apply the sin function.
                    Other cases require the training examples to be pre-computed, e.g. a network that is supposed to recognise
                    letters in an image, since this cannot precisely be calculated directly.
               </p>

               <div id="img">
               
                    <img src="images/graphs/I=50k R=0.1 N=15 L=3.png" />
                    
               </div>

                <p>
                    This graph shows how the average total error of a network decreases as back propagation teaches the network
                    using 50,000 examples. The network trained is a two input and two output network with 15 neurons in each of
                    the 3 hidden layers used to convert Cartesian coordinates to polar coordinates.
                </p>
                
                <h1>The Algorithm</h1>

                <h2>Initialisation</h2>
                
                <p>
                    Before the back propagation is run, the weights of all synapses in the network are initialised to small random
                    values, usually between -1 and 1. The range of the initial values is not important so long as the weights are
                    not all equal, in this case, back propagation will change each weight by the same amount and the behaviour of
                    the network will never change significantly.
                </p>

                <h2>Train Test Loop</h2>
                
                <p>
                    Once all weights are initialised, apply an input in the training examples to the network and measure the error for
                    each output of the network which is simply the difference between the actual outputs and the expected outputs.
                </p>

                <h3>Error Propagation</h3>
                
                <p>
                    The first step of the training is to propagate the errors backwards by computing the delta value, or error
                    value of each neuron in the hidden layer. To help describe the process, the following network with two hidden
                    layers of three neurons will be used as an example:
                </p>

               <div id="img">
               
                    <img src="images/Network.png" />
                    
               </div>
                
                <p>
                    The delta values are calculated layer by layer, from the last hidden layer to the first. If there are no
                    hidden layers in the network this step can be skipped.
                </p>
                
                <p>
                    The delta value of each neuron in the last hidden layer is calculated by multiplying the weight of each synapse
                    leaving the neuron by the error of the output which the synapse connects to. All weight-error products of a
                    neuron are then summed to give the final delta value of that neuron.
                </p>
               
                <p>
                    The diagram below illustrates how the delta value for the topmost hidden neuron is calculated. As stated above,
                    this process is repeated for each neuron in the current layer with the corresponding weights.
                </p>

               <div id="img">
               
                    <img src="images/Delta 1.png" />
                    
               </div>
                
                <p>
                    If the network contains more than one hidden layer, then each subsequent layer is visited and the delta value
                    of each neuron in the layer is calculated as before. However, the delta values of the previous layer are used
                    instead of the error values.
                </p>
                
                <p>
                    The diagram below shows how the delta values for a neuron in the first hidden layer is calculated using delta values
                    from the previous layer.
                    
                </p>

               <div id="img">
               
                    <img src="images/Delta 2.png" />
                    
               </div>
                
                <p>
                    The procedure described here is equivalent to running the network backwards, by using the error values as an input
                    which is given to the output neurons then propagated through the network to the input layer, storing the input
                    of each neuron as its delta value and ignoring the activation function.
                </p>

                <h3>Weight Adjustment</h3>
                
                <p>
                    Finally, each synaptic weight is adjusted by the product of the learning rate, the input to the synapse, the
                    delta value of the neuron which the synapse connects to and gradient of the activation function at the output
                    of the synapse (or the input of the neuron).
                </p>
                
                [D3]

                <p>
                    The final set of synapses leading to the output layer are adjusted by the same product without the gradient
                    term, as the output neurons do not apply the activation function. The error propagation and weight adjustment
                    is repeated until the errors reduce below a value acceptable to the designer of the network.
                </p>

                <h2>Learning Rate and Momentum</h2>

                <p>
                    The learning rate is used to prevent overshooting the target; this happens when the
                    network learns too quickly, so this value needs to be low (usually around 0.1), but if it is too low the
                    network will learn very slowly.
                </p>
                
                <p>
                    One workaround for this is dynamically changing the rate using a function; when the network is first started
                    the rate could be higher to make rougher adjustments and then lowered later to fine tune the weights near the
                    end of the training. The downside of this is that it can be hard to find the optimal rate for each stage of
                    the network - if it doesn't decrease quick enough, then the network will learn too quickly and overshoot the
                    optimal set of weights leading it to overcompensate continually and oscillate around the optimal weights.
                </p>
                
                <p>
                    Instead, the rate of learning is adjusted by adding the momentum term to the weight update equation in place
                    of the multiplied by the learning rate. The momentum term is simply the previous weight adjustment (intially
                    zero) multipied by the momentum constant. This influences the weights in the direction previously travelled
                    which prevents the network oscillating and speeds up the initial learning stage where the weights are adjusted
                    in the same direction over many iterations.
                </p>

                <h1>Pseudo code</h1>
                
                <p>
                    Below is pseudo code implementing back propagation on a network with one hidden layer. This can be extended
                    to support a network with a variable number of layers.
                </p>
                           
                <pre class="brush: pas; gutter: false; toolbar: false;">
                
                    procedure backPropagation():

                        inputs := getInput()

                        expected := getExpected(inputs)
                        actual := runNetwork(inputs)

                        errors := calculateErrors(expected, actual)

                        // 1: Calculate the delta values of the hidden neurons.
                        for n := 0 to hiddenNeuronCount:
                            sum := 0
                            for o := 0 to outputCount:
                                sum := sum + weightsOut[n, o] * errors[o]
                            endfor
                            deltas[n] := sum
                        endfor

                        // 2: Adjust the weights between the input and hidden neurons
                        for i := 0 to inputCount:
                            for n := 0 to hiddenNeuronCount:
                                weightsIn[i, n] := weightsIn[i, n] + learningRate
                                    * inputs[i] * deltas[n] * dLogistic(hiddenOut[n])
                            endfor
                        endfor

                        // 3: Adjust the weights between the hidden and output neurons
                        for n := 0 to hiddenNeuronCount:
                            for o := 0 to outputCount:
                                weightsOut[n, o] := weightsOut[n, o] + learningRate
                                    * hiddenOut[n] * errors[o]
                            endfor
                        endfor

                        repeat procedure until inputs exhausted
                            or total error acceptable
                        
                    endprocedure
                    
                </pre>
                
                <p>
                    The weight update performed in section 2 of the pseudo code shows the derivative of the activation function
                    taking the output of the current hidden neuron as its input instead of the input of the hidden neuron as stated
                    in weight adjustment section above. This is because the derivative of the logistics function can be defined only
                    in terms of the output of the function:
                </p>
                
                <div id="img">
                    
                    Logistics(x) = 1 / (1 + exp(-x))
                    
                </div>
                
                <div id="img">
                    
                    dLogistics(x)/dx = Logistics(x) * (1 - Logistics(x))
                    
                </div>
                
                <p>
                    This saves space by removing the need to store the input of each neuron when calculating the outputs of the
                    network.
                </p>

                <h1>Intuition</h1>

                <p>
                    The previous section describes how the back propagation algorithm teaches a network, but not why. As stated
                    before, back propagation applies an input to the network and measures the error between the expected and actual
                    outputs. These errors can be brought down to zero in a single layer network if the network were given the same
                    inputs again by adjusting the weights of synapses leading to the output neurons using the delta rule:
                </p>
                
                <div id="img">
                
                    deltaW = learning rate * error * gradient of activation fuction at input * output
                
                </div>

                <p>
                    Where ??? is the weight between hidden neuron ??? and output ???, ??? is the error at ??? and ??? is the output
                    of ???.
                </p>
                
                <p>
                    This will train a single layer network but cannot be applied to multilayer networks because the error value
                    of each neuron is unknown. However, running the network in reverse with the error values as described above,
                    gives a value for the amount which the neuron contributed to the errors in the next layer. This delta value
                    can then be used as the error value in the delta rule, giving the weight update equation.
                </p>

                <h1>Limitations</h1>

                <p>
                    There are some problems associated with the back propagation algorithm. For instance, it might not find a solution
                    - there is not guarantee that the network will reach its target. The network is also very sensitive to the number
                    of hidden layers. If there are too little, it might not be able to learn what you want it to, but if there are too
                    many then it will learn very slowly. This means that a neural network has to be reconfigured for each function you
                    want it to do, unless they are similar. This takes a lot of time, and requires some experience to get right without
                    resorting to trial and error.
                </p>
                
                <p>
                    Also, as mentioned before, the speed at which a neural network will learn depends on the learning rate, but the
                    learning rate cannot be set to high without risking oscillations. This marks a fairly severe limitation on back
                    propagation and greatly reduces its speed.
                </p>
                
                <h1>References</h1>
                
                <div id="ref">

                <ul>
                    <li>
                        <a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html">
                          http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</a>
                    </li>
                    
                    <li>
                        <a href="http://www.learnartificialneuralnetworks.com/backpropagation.html">
                          http://www.learnartificialneuralnetworks.com/backpropagation.html</a>
                    </li>
                    
                    <li>
                        Turing Omnibus reference.
                    </li>
                    
                    <li>
                        <a href="http://itee.uq.edu.au/~cogs2010/cmc/chapters/BackProp/index2.html">
                          http://itee.uq.edu.au/~cogs2010/cmc/chapters/BackProp/index2.html</a>
                    </li>
                    
                    <li>
                        <a href="http://en.wikiversity.org/wiki/Learning_and_neural_networks">
                          http://en.wikiversity.org/wiki/Learning_and_neural_networks</a>
                    </li>
                    
                    <li>
                        <a href="http://msdn.microsoft.com/en-us/magazine/jj658979.aspx">
                          http://msdn.microsoft.com/en-us/magazine/jj658979.aspx</a>
                    </li>
                </ul>
                
                </div>
		       			  
		    </div>
		    
		    <div id="rightcolumn">
            </div>
		    

        </div>	   
        
        <div id="footer">
		     
              Imperial College Computing		

        </div>
         
    </div>
   
</body>

</html>
