<!doctype html>

<html>

<head>

    <title>Neural Networks and their applications</title>
    <link rel="stylesheet" type="text/css" href="css/main.css" />
    
    <script type="text/javascript" src="js/shCore.js"></script>
    <script type="text/javascript" src="js/shBrushDelphi.js"></script>
    <link rel="stylesheet" type="text/css" href="css/shCoreDefault.css" />
    <script type="text/javascript">SyntaxHighlighter.all()</script>
    
</head>

<body>

    <div id="wrapper">

        <a href="index.html" id="header"></a>	 

        <div id="navigation">
<script type='text/javascript' src='https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js'></script>
<script type='text/javascript'>
$(function() {
    // Stick the #nav to the top of the window
    var nav = $('#navigation');
    var navHomeY = nav.offset().top;
    var isFixed = false;
    var $w = $(window);
    $w.scroll(function() {
        var scrollTop = $w.scrollTop();
        var shouldBeFixed = scrollTop > navHomeY;
        if (shouldBeFixed && !isFixed) {
            nav.css({
                position: 'fixed',
                top: 0,
                left:  nav.offset().left,
                width: nav.width()
            });
            isFixed = true;
        }
        else if (!shouldBeFixed && isFixed)
        {
            nav.css({
                padding: 9,
                left: 0,
                position: 'relative'
           
            });
            isFixed = false;
        }
    });
});
</script>

            <ul id="nav-one" class="nav">

                <li>
                    <a href="introduction.html">Introduction</a>
                </li>

                <li>
                    <a href="perceptrons.html">Perceptrons</a>
                </li>

                <li>
                    <a href="backpropagation.html">Backpropagation</a>
                </li>

                <li>
                    <a href="applet.html">Applet</a>
                </li>
                
            </ul>
            
        </div>
 
        <div id="faux">
        
            <div id="leftcolumn">
		    </div>
		    
		    <div id="content">

                <h1>Back Propagation</h1>
                
                <p>
                    In large neural networks simulating more complex behaviours, finding the weights of each synapse is too complex
                    to be done manually, so instead the back propagation algorithm is commonly used to find weights which will
                    approximate the desired behaviour.
                </p>
                
                <p>
                    Back propagation is a supervised learning algorithm which works by calculating the difference between each output of
                    the network and the expected output for the inputs to the network, then propagating this error backwards
                    through the network to adjust the weights and reduce the error in the future. By repeating this train and test
                    loop over a large range of valid inputs, the neural network will learn the expected behaviour and the errors
                    will decrease.
                </p>
                
                <p>
                    Back propagation can be run for any number of valid inputs, however the network will eventually
                    reach a state where back propagation can no longer reduce the average error as shown below. In some cases,
                    the inputs used to
                    train the network can be picked randomly and the expected output can be found without manual intervention
                    since they are simple enough to calculate, e.g. a network trained to add numbers or apply the sin function.
                    Other cases require the training examples to be pre-computed, e.g. a network that is supposed to recognise
                    letters in an image, since this cannot precisely be calculated directly.
               </p>

               <div id="img">
               
                    <img src="images/graphs/I=50k R=0.1 N=15 L=3.png" title="I=50k R=0.1 N=15 L=3"/>
                    <p>Image source: created with applet</p>
                    
               </div>

                <p>
                    This graph shows how the average total error of a network decreases as back propagation teaches the network
                    using 50,000 examples. The network trained is a two input and two output network with 15 neurons in each of
                    the 3 hidden layers used to convert Cartesian coordinates to polar coordinates.
                </p>
                
                <h1>The Algorithm</h1>

                <h2>Initialisation</h2>
                
                <p>
                    Before the back propagation is run, the weights of all synapses in the network are initialised to small random
                    values, usually between -1 and 1. The range of the initial values is not important so long as the weights are
                    not all equal, in this case, back propagation will change each weight by the same amount and the behaviour of
                    the network will never change significantly.
                </p>

                <h2>Train Test Loop</h2>
                
                <p>
                    Once all weights are initialised, apply an input in the training examples to the network and measure the error for
                    each output of the network which is simply the difference between the actual outputs and the expected outputs.
                </p>

                <h3>Error Propagation</h3>
                
                <p>
                    The first step of the training is to propagate the errors backwards by computing the delta value, or error
                    value of each neuron in the hidden layer. To help describe the process, the following network with two hidden
                    layers of three neurons will be used as an example:
                </p>

               <div id="img">
               
                    <img src="images/Network.png" title="Network diagram" />
                    <p>Image source: created by Christophe Steininger</p>
                    
               </div>
                
                <p>
                    The delta values are calculated layer by layer, from the last hidden layer to the first. If there are no
                    hidden layers in the network this step can be skipped.
                </p>
                
                <p>
                    The delta value of each neuron in the last hidden layer is calculated by multiplying the weight of each synapse
                    leaving the neuron by the error of the output which the synapse connects to. All weight-error products of a
                    neuron are then summed to give the final delta value of that neuron.
                </p>
               
                <p>
                    The diagram below illustrates how the delta value for the topmost hidden neuron is calculated. As stated above,
                    this process is repeated for each neuron in the current layer with the corresponding weights.
                </p>

               <div id="img">
               
                    <img src="images/Delta 1.png" title="Network diagram 2" />
                    <p>Image source: created by Christophe Steininger</p>
               </div>
                
                <p>
                    If the network contains more than one hidden layer, then each subsequent layer is visited and the delta value
                    of each neuron in the layer is calculated as before. However, the delta values of the previous layer are used
                    instead of the error values.
                </p>
                
                <p>
                    The diagram below shows how the delta values for a neuron in the first hidden layer is calculated using delta values
                    from the previous layer.
                    
                </p>

               <div id="img">
               
                    <img src="images/Delta 2.png" title="Network diagram 3" />
                    <p>Image source: created by Christophe Steininger</p>
               </div>
                
                <p>
                    The procedure described here is equivalent to running the network backwards, by using the error values as an input
                    which is given to the output neurons then propagated through the network to the input layer, storing the input
                    of each neuron as its delta value and ignoring the activation function.
                </p>

                <h3>Weight Adjustment</h3>
                
                <p>
                    Finally, each synaptic weight in the network is adjusted, as shown in the diagram below, by the product of the
                    learning rate <em>LR</em>, the input to the synapse <em>I</em>, the delta value of the neuron which the synapse
                    connects to <em>d<sub>n</sub></em> and gradient of the activation function at the output of the synapse
                    (or the input of the neuron) <em>da/dx(O)</em>. Here, <em>a(x)</em> is the activation function and
                    <em>O</em> is the output of the neuron where the activation function has not yet been applied.
                </p>
                
                <div id="img">
                
                    <img src="images/Weight Update.png" title="Weight update equation" />
                    <p>Image source: created by Christophe Steininger</p>
                </div>

                <p>
                    The final set of synapses leading to the output layer are adjusted by the same product without the gradient
                    term, as the output neurons do not apply the activation function. The error propagation and weight adjustment
                    is repeated until the errors reduce below a value acceptable to the designer of the network.
                </p>

                <h2>Learning Rate and Speed Improvements</h2>

                <p>
                    The learning rate is used to prevent overshooting the target; this happens when the network learns too quickly,
                    so this value needs to be low (usually around 0.1), but if it is too low the network will learn very slowly.
                    Usually, the learning rate is set to the largest possible value which does not overshoot the target; this value is
                    normally determined by trial and error. However, small weight adjustments are only needed near the end of the
                    training when the network is close to the optimal values, so larger adjustments could be made at the start of
                    the training.
                </p>
                
                <p>
                    One method for achieving this is to dynamically change the rate using a function; when the network is first started
                    the rate can be high to make rougher adjustments and then lowered later to fine tune the weights near the
                    end of the training. The downside of this approach is that it can be hard to find the optimal rate for each
                    stage of the training - if the rate doesn't decrease fast enough, then the network will learn too quickly
                    and overshoot the optimal set of weights leading it to overcompensate continually and oscillate around the
                    optimal weights.
                </p>
                
                <p>
                    A better approach is to add the momentum term to the weight update equation. The momentum term is simply the
                    previous weight adjustment <em>d<sub>w</sub>(t)</em> (initially zero) multiplied by the momentum constant
                    <em>M</em>. This influences the weights in the direction previously travelled which prevents the network
                    oscillating and speeds up the initial learning stage where the weights are adjusted in the same direction over
                    many iterations.
                </p>
                
                <div id="img">
                
                    <img src="images/Momentum Weight Update.png" title="Weight update equation with momentum" />
                    <p>Image source: created by Christophe Steininger</p>
                
                </div>

                <h1>Pseudo code</h1>
                
                <p>
                    Below is pseudo code implementing back propagation on a network with one hidden layer. This can be extended
                    to support a network with a variable number of layers.
                </p>
                           
                <pre class="brush: pas; gutter: false; toolbar: false;">
                
                    procedure backPropagation():

                        inputs := getInput()

                        expected := getExpected(inputs)
                        actual := runNetwork(inputs)

                        errors := calculateErrors(expected, actual)

                        // 1: Calculate the delta values of the hidden neurons.
                        for n := 0 to hiddenNeuronCount:
                            sum := 0
                            for o := 0 to outputCount:
                                sum := sum + weightsOut[n, o] * errors[o]
                            endfor
                            deltas[n] := sum
                        endfor

                        // 2: Adjust the weights between the input and hidden neurons
                        for i := 0 to inputCount:
                            for n := 0 to hiddenNeuronCount:
                                weightsIn[i, n] := weightsIn[i, n] + learningRate
                                    * inputs[i] * deltas[n] * dLogistic(hiddenOut[n])
                            endfor
                        endfor

                        // 3: Adjust the weights between the hidden and output neurons
                        for n := 0 to hiddenNeuronCount:
                            for o := 0 to outputCount:
                                weightsOut[n, o] := weightsOut[n, o] + learningRate
                                    * hiddenOut[n] * errors[o]
                            endfor
                        endfor

                        repeat procedure until inputs exhausted
                            or total error acceptable
                        
                    endprocedure
                    
                </pre>
                
                <p>
                    The weight update performed in section 2 of the pseudo code shows the derivative of the activation function
                    taking the output of the current hidden neuron as its input instead of the input of the hidden neuron as stated
                    in weight adjustment section above. This is because the derivative of the logistics function can be defined only
                    in terms of the function itself:
                </p>
                
                <div id="img">
                    
                    <em>logistics(x) = 1 / (1 + exp(-x))</em>
                    
                </div>
                
                <div id="img">
                    
                    <em>dlogistics(x)/dx = logistics(x) * (1 - logistics(x))</em>
                    
                </div>
                
                <p>
                    This is a useful property as it saves space by removing the need to store the input of each neuron when
                    calculating the outputs of the network from a training example.
                </p>

                <h1>Intuition</h1>

                <p>
                    The previous section describes how the back propagation algorithm teaches a network, but not why. As stated
                    before, back propagation applies an input to the network and measures the error between the expected and actual
                    outputs. These errors can be brought down to zero in a single layer network if the network were given the same
                    inputs again by adjusting the weights of synapses leading to the output neurons using the delta rule:
                </p>
                
                <div id="img">
                
                    <em>d<sub>W<sub>i,j</sub></sub> = LR * I<sub>i</sub> * E<sub>j</sub></em>
                
                </div>

                <p>
                    Where <em>d<sub>W<sub>i,j</sub></sub></em> is change in weight between hidden neuron <em>i</em> and output
                    neuron <em>j</em>, <em>LR</em> is the learning rate, <em>I<sub>i</sub></em> is the output of neuron <em>i</em>
                    and <em>E<sub>j</sub></em> is the error of output neuron <em>j</em>.
                </p>
                
                <p>
                    This will train a single layer network but cannot be applied to multilayer networks because the error value
                    of each neuron is unknown. However, running the network in reverse with the error values as described above,
                    gives a value for the amount which the neuron contributed to the errors in the next layer. This delta value
                    can then be used as the error value in the delta rule, giving the weight update equation. The final factor,
                    the derivative of the activation function is included to ensure that the weight is adjusted in the direction
                    which will reduce the error.
                </p>

                <h1>Limitations</h1>
                
                <p>
                    Back propagation is not guaranteed to find the best possible set of weights for the problem it is applied to.
                    The algorithm will settle in a local error minimum if encountered instead of the global error minimum. This means
                    that back propagation will not adjust the weights in a way such that the error will temporary increase before
                    decreasing past the previous minimum. This can countered by introducing the momentum term in the weight update
                    calculation, but the momentum term may not give the network enough inertia to move past the local minimums.
                </p>

                <p>
                    Besides this, back propagation is slow due to the large amount of iterations and calculations per iteration
                    which have to be performed. The speed can be improved by running an iteration for each processor in the machine
                    then adjusting each weight in the network by the sum of the weight adjustments given by each thread. Even with
                    this multithreaded approach, training very large networks for complex problems is time consuming.
                </p>
                
                <p>
                    Also, as mentioned before, the speed at which a neural network will learn depends on the learning rate, but the
                    learning rate cannot be set to high without risking oscillations. This marks a fairly severe limitation on back
                    propagation and greatly reduces its speed.
                </p>
                
                <h1>References</h1>
                
                <div id="ref">

                <ol>
                    <li>
                        <a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html">
                          http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</a>
                    </li>
                    
                    <li>
                        <a href="http://www.learnartificialneuralnetworks.com/backpropagation.html">
                          http://www.learnartificialneuralnetworks.com/backpropagation.html</a>
                    </li>
                    
                    <li>
                        <a href="http://itee.uq.edu.au/~cogs2010/cmc/chapters/BackProp/index2.html">
                          http://itee.uq.edu.au/~cogs2010/cmc/chapters/BackProp/index2.html</a>
                    </li>
                    
                    <li>
                        <a href="http://en.wikiversity.org/wiki/Learning_and_neural_networks">
                          http://en.wikiversity.org/wiki/Learning_and_neural_networks</a>
                    </li>
                    
                    <li>
                        <a href="http://msdn.microsoft.com/en-us/magazine/jj658979.aspx">
                          http://msdn.microsoft.com/en-us/magazine/jj658979.aspx</a>
                    </li>
                    
                    <li>
                        A. K. Dewdney (1993). <em>The New Turning Omibus.</em> New York: W. H. Freeman and Company. p241-248.
                    </li>
                </ol>
                
                </div>
		       			  
		    </div>
		    
		    <div id="rightcolumn">
            </div>
		    

        </div>	   
        
        <div id="footer">
		     
              Imperial College Computing		

        </div>
         
    </div>
   
</body>

</html>
